{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 14:21:46.148471] Search object created\n",
      "[2024-11-27 14:21:46.180106] Request submitted\n",
      "[2024-11-27 14:21:46.180126] Request ID: 88123fa8-f005-40d9-892a-542151629bf7\n",
      "[2024-11-27 14:21:46.180130] Request details available at: https://api.aurorax.space/api/v1/ephemeris/requests/88123fa8-f005-40d9-892a-542151629bf7\n",
      "[2024-11-27 14:21:46.180133] Waiting for data ...\n",
      "[2024-11-27 14:21:47.620988] Checking for data ...\n",
      "[2024-11-27 14:21:48.064039] Data is now available\n",
      "[2024-11-27 14:21:48.064265] Retrieving data ...\n",
      "[2024-11-27 14:21:49.915099] Retrieved 18.7 MB of data containing 5407 records\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import datetime\n",
    "import pprint\n",
    "import pyaurorax\n",
    "aurorax = pyaurorax.PyAuroraX()\n",
    "\n",
    "\n",
    "#  To begin, let's do an ephemeris search for some THEMIS ASI data.\n",
    "\n",
    "# We will search for any data between these dates\n",
    "start = datetime.datetime(2008, 1, 1, 0, 0, 0)\n",
    "end = datetime.datetime(2008, 1, 31, 23, 59, 59)\n",
    "programs = [\"themis-asi\"]\n",
    "\n",
    "# Now, to filter based on ML data, we need to set up some metadata\n",
    "# filters. Let's filter to only retrieve records which the\n",
    "# 'calgary_apa_ml_v1' ML dataset classified as APA, with a confidence\n",
    "# greater than or equal to 95%.\n",
    "#\n",
    "# This is done as below ...\n",
    "metadata_filters_logical_operator = \"AND\"\n",
    "metadata_filters = [\n",
    "          {\n",
    "            \"key\": \"calgary_apa_ml_v1\",     #\n",
    "            \"operator\": \"in\",               #   Here, we set up the metadata filter to retrieve\n",
    "            \"values\": [                     #   only records that were classified as APA....\n",
    "              \"classified as APA\"           #\n",
    "            ]\n",
    "          },\n",
    "          {\n",
    "            \"key\": \"calgary_apa_ml_v1_confidence\",\n",
    "            \"operator\": \">=\",                         # ... with a confidence of \n",
    "            \"values\": [                               # at least 95%\n",
    "              \"95\"\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "\n",
    "# Perform the search\n",
    "s = aurorax.search.ephemeris.search(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    programs=programs,\n",
    "    metadata_filters_logical_operator=metadata_filters_logical_operator,\n",
    "    metadata_filters=metadata_filters,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 30), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.7499007670771, lon=-172.0643415195183), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 31), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.74990082859775, lon=-172.06434121158588), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 32), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.74990089011834, lon=-172.06434090365335), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 33), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.749900951639, lon=-172.06434059572092), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 34), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.74990101315964, lon=-172.0643402877885), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 35), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.74990107468032, lon=-172.06433997985604), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 36), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.7499011362009, lon=-172.06433967192348), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 37), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.74990119772151, lon=-172.06433936399102), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 38), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.74990125924215, lon=-172.06433905605851), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...)),\n",
      " EphemerisData(epoch=datetime.datetime(2008, 1, 1, 11, 39), location_geo=Location(lat=61.755798, lon=-121.227005), location_gsm=Location(lat=None, lon=None), nbtrace=Location(lat=61.755798, lon=-121.227005), sbtrace=Location(lat=-64.74990132076276, lon=-172.06433874812603), metadata={'clausen_ml_oath': ...}, data_source=DataSource(...))]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 records\n",
    "pprint.pprint(s.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: classified as APA\n",
      "Confidence: 99.96\n"
     ]
    }
   ],
   "source": [
    "# Access the classification of interest\n",
    "print(\"Classification:\", s.data[0].metadata['calgary_apa_ml_v1'])\n",
    "print(\"Confidence:\", s.data[0].metadata['calgary_apa_ml_v1_confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                calgary_apa_ml_v1    confidence        \n",
      "====================================================================\n",
      "2008-01-01 11:30:00      classified as APA      99.96              \n",
      "2008-01-01 11:31:00      classified as APA      99.96              \n",
      "2008-01-01 11:32:00      classified as APA      99.96              \n",
      "2008-01-01 11:33:00      classified as APA      99.96              \n",
      "2008-01-01 11:34:00      classified as APA      99.96              \n",
      "2008-01-01 11:35:00      classified as APA      99.96              \n",
      "2008-01-01 11:36:00      classified as APA      99.96              \n",
      "2008-01-01 11:37:00      classified as APA      99.96              \n",
      "2008-01-01 11:38:00      classified as APA      99.96              \n",
      "2008-01-01 11:39:00      classified as APA      99.96              \n"
     ]
    }
   ],
   "source": [
    "# Let's print the results of the first 10 records as a table\n",
    "print(f\"{'Timestamp':<{25}}\"\n",
    "      f\"{'calgary_apa_ml_v1':<{20}} \"\n",
    "      f\"{'confidence':<{18}}\")\n",
    "print(\"====================================================================\")\n",
    "for i in range(10):\n",
    "    timestamp_str = s.data[i].epoch.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"{timestamp_str:<{25}}\"\n",
    "          f\"{s.data[i].metadata['calgary_apa_ml_v1']:<{20}} \"\n",
    "          f\"  {s.data[i].metadata['calgary_apa_ml_v1_confidence']:<{18}} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 14:21:49.937189] Search object created\n",
      "[2024-11-27 14:21:49.956997] Request submitted\n",
      "[2024-11-27 14:21:49.957020] Request ID: 597609e8-0a61-470d-a879-7677d70df75a\n",
      "[2024-11-27 14:21:49.957024] Request details available at: https://api.aurorax.space/api/v1/ephemeris/requests/597609e8-0a61-470d-a879-7677d70df75a\n",
      "[2024-11-27 14:21:49.957027] Waiting for data ...\n",
      "[2024-11-27 14:21:51.374502] Checking for data ...\n",
      "[2024-11-27 14:21:51.795770] Data is now available\n",
      "[2024-11-27 14:21:51.796000] Retrieving data ...\n",
      "[2024-11-27 14:21:52.089026] Retrieved 2.0 MB of data containing 565 records\n"
     ]
    }
   ],
   "source": [
    "# Now, let's instead search for data, and filter out cloudy\n",
    "# data. We set up our metadata filter as follows, to filter\n",
    "# and only retrieve data that was classified as not cloudy\n",
    "# with a confidence > 90%\n",
    "\n",
    "# set up search parameters, we will restrict this search to one site, Gillam\n",
    "start = datetime.datetime(2008, 1, 1, 0, 0, 0)\n",
    "end = datetime.datetime(2008, 1, 7, 23, 59, 59)\n",
    "programs = [\"themis-asi\"]\n",
    "platforms = [\"gillam\"]\n",
    "\n",
    "metadata_filters_logical_operator = \"AND\"\n",
    "metadata_filters = [\n",
    "          {\n",
    "            \"key\": \"calgary_cloud_ml_v1\",\n",
    "            \"operator\": \"in\",\n",
    "            \"values\": [\n",
    "              \"classified as not cloudy\"\n",
    "            ]\n",
    "          },\n",
    "          {\n",
    "            \"key\": \"calgary_cloud_ml_v1_confidence\",\n",
    "            \"operator\": \">\",\n",
    "            \"values\": [\n",
    "              \"90\"\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "\n",
    "# Perform the search\n",
    "s = aurorax.search.ephemeris.search(start=start,\n",
    "                                    end=end,\n",
    "                                    programs=programs,\n",
    "                                    platforms=platforms,\n",
    "                                    metadata_filters_logical_operator=metadata_filters_logical_operator,\n",
    "                                    metadata_filters=metadata_filters,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                Classification               Confidence        \n",
      "====================================================================\n",
      "2008-01-01 23:28:00      classified as not cloudy       91.81              \n",
      "2008-01-01 23:29:00      classified as not cloudy       91.81              \n",
      "2008-01-02 00:00:00      classified as not cloudy       99.96              \n",
      "2008-01-02 00:01:00      classified as not cloudy       99.96              \n",
      "2008-01-02 00:02:00      classified as not cloudy       99.96              \n",
      "2008-01-02 00:03:00      classified as not cloudy       99.96              \n",
      "2008-01-02 00:04:00      classified as not cloudy       99.96              \n",
      "2008-01-02 00:05:00      classified as not cloudy       99.96              \n",
      "2008-01-02 00:06:00      classified as not cloudy       99.96              \n",
      "2008-01-02 00:07:00      classified as not cloudy       99.96              \n"
     ]
    }
   ],
   "source": [
    "# Again, print some results\n",
    "print(f\"{'Timestamp':<{25}}\"\n",
    "      f\"{'Classification':<{28}} \"\n",
    "      f\"{'Confidence':<{18}}\")\n",
    "print(\"====================================================================\")\n",
    "for i in range(10):\n",
    "    timestamp_str = s.data[i].epoch.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"{timestamp_str:<{25}}\"\n",
    "          f\"{s.data[i].metadata['calgary_cloud_ml_v1']:<{28}} \"\n",
    "          f\"  {s.data[i].metadata['calgary_cloud_ml_v1_confidence']:<{18}} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-27 14:21:52.102043] Search object created\n",
      "[2024-11-27 14:21:52.123472] Request submitted\n",
      "[2024-11-27 14:21:52.123495] Request ID: 2e5a9be2-24d5-4a57-9cf5-5081c440dc56\n",
      "[2024-11-27 14:21:52.123498] Request details available at: https://api.aurorax.space/api/v1/ephemeris/requests/2e5a9be2-24d5-4a57-9cf5-5081c440dc56\n",
      "[2024-11-27 14:21:52.123501] Waiting for data ...\n",
      "[2024-11-27 14:21:53.546379] Checking for data ...\n",
      "[2024-11-27 14:21:54.969656] Checking for data ...\n",
      "[2024-11-27 14:21:55.382282] Data is now available\n",
      "[2024-11-27 14:21:55.382520] Retrieving data ...\n",
      "[2024-11-27 14:21:58.515132] Retrieved 31.6 MB of data containing 9156 records\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's gather some data based on classifications\n",
    "# using the OATH model. Let's filter so that we obtain\n",
    "# records that were classified as either discrete or diffuse aurora.\n",
    "\n",
    "# set up search parameters\n",
    "start = datetime.datetime(2008, 1, 1, 0, 0, 0)\n",
    "end = datetime.datetime(2008, 1, 7, 23, 59, 59)\n",
    "programs = [\"themis-asi\"]\n",
    "\n",
    "metadata_filters_logical_operator = \"AND\"\n",
    "metadata_filters = [\n",
    "          {\n",
    "            \"key\": \"clausen_ml_oath\",\n",
    "            \"operator\": \"in\",\n",
    "            \"values\": [\n",
    "              \"classified as diffuse\",\n",
    "              \"classified as discrete\",\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "\n",
    "# Perform the search\n",
    "s = aurorax.search.ephemeris.search(start=start,\n",
    "                                    end=end,\n",
    "                                    programs=programs,\n",
    "                                    metadata_filters_logical_operator=metadata_filters_logical_operator,\n",
    "                                    metadata_filters=metadata_filters,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                   Classification    \n",
      "=================================================\n",
      "2008-01-01 01:11:00      classified as discrete \n",
      "2008-01-01 01:19:00      classified as diffuse \n",
      "2008-01-01 01:20:00      classified as diffuse \n",
      "2008-01-01 01:22:00      classified as discrete \n",
      "2008-01-01 01:25:00      classified as diffuse \n",
      "2008-01-01 01:26:00      classified as diffuse \n",
      "2008-01-01 01:27:00      classified as diffuse \n",
      "2008-01-01 01:28:00      classified as diffuse \n",
      "2008-01-01 01:29:00      classified as diffuse \n",
      "2008-01-01 01:30:00      classified as diffuse \n"
     ]
    }
   ],
   "source": [
    "# Again, print some results\n",
    "print(f\"{'Timestamp':<{28}}\"\n",
    "      f\"{'Classification':<{18}}\")\n",
    "print(\"=================================================\")\n",
    "\n",
    "for i in range(10):\n",
    "    timestamp_str = s.data[i].epoch.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"{timestamp_str:<{23}}\"\n",
    "          f\"  {s.data[i].metadata['clausen_ml_oath']:<{18}} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyaurorax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
